# AI-Enhanced Open Data Lakehouse 
## Sentiment Analysis Using â„ï¸ Snowflake Cortex AI on Iceberg Tables
## ğŸ§Š Overview
This repository contains a comprehensive guide to integrating artificial intelligence (AI) into open data lakehouses using Snowflake Cortex AI and Apache Iceberg tables. With the recent advancements in Snowflake, including the general availability of Snowflake Cortex AI and Iceberg tables, this repository aims to equip you with the necessary knowledge and tools to build and automate your open data lakehouse.
## ğŸ”§ Features
- Creation and management of Iceberg Tables in Snowflake.
- Loading data to Iceberg Tables using Snowpark.
- Utilizing Large Language Model (LLM) functions to generate sentiment predictions.
- Automating Change Data Capture (CDC) pipelines using Streams and Tasks.
- Hands-on experience with Snowflake Notebooks (currently in public preview).
## ğŸ“‹ Prerequisites
To follow this guide, you should have:
- Familiarity with Snowflake
- Familiarity with cloud object storage
- Proficiency in SQL
- Proficiency in Python
- Understanding of Apache Iceberg
## ğŸ’¡ What You'll Learn
- How to effectively use Snowflake Notebooks for data exploration and analysis.
- Creating a Snowflake-managed Iceberg table for organizing your data.
- Loading and transforming data into Iceberg Tables using Snowpark.
- Implementing LLM functions to derive meaningful sentiment predictions from data.
- Setting up and automating CDC pipelines with Streams and Tasks for real-time data processing.
## âš™ï¸ What You'll Need
- A Snowflake account with access to the ACCOUNTADMIN role. A free trial account will suffice, with the Standard Edition suitable for this lab.
- The account must reside in one of the following regionsğŸŒ:
  - AWS US West 2 (Oregon)
  - AWS US East 1 (N. Virginia)
  - AWS Europe Central 1 (Frankfurt)
  - ğŸ‡ºğŸ‡¸ Azure East US 2 (Virginia)
  - ğŸ‡³ğŸ‡± Azure West Europe (Netherlands)
- A cloud storage bucket in the same region and from the same cloud provider as your Snowflake account. Direct credential access is required as storage integrations are not supported for External Volumes.
## ğŸ› ï¸ What You'll Build
By completing this guide, you will build:
- An open data lakehouse utilizing Iceberg for efficient data management.
- An automated CDC pipeline that processes data using an LLM, enhancing your data analytics capabilities.
## ğŸš€ Getting Started
To begin, clone this repository and follow the step-by-step instructions provided in the ### snowflake notebook. 
The guide is structured to help you set up your environment, understand the necessary concepts, and implement the required solutions seamlessly.

## ğŸ¤ Contributing
Contributions are welcome! If you have suggestions for improvements or new features, please open an issue or submit a pull request.
---
With this guide, you'll be well-equipped to harness the power of AI and Snowflake's capabilities to create an effective open data lakehouse. Happy coding! ğŸš€