{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1aa0dc-3107-498a-bc12-6747476d7565",
   "metadata": {
    "collapsed": false,
    "name": "md_snowflake_objects"
   },
   "source": [
    "# Create Snowflake Objects\n",
    "\n",
    "Create database and warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17d761-5c1b-48a0-bd12-5ce5e252f605",
   "metadata": {
    "language": "sql",
    "name": "db_creation"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE DATABASE ICEBERG_DEMO;\n",
    "CREATE OR REPLACE WAREHOUSE demo_wh;\n",
    "\n",
    "USE DATABASE ICEBERG;\n",
    "USE WAREHOUSE demo_wh;\n",
    "\n",
    "use role ACCOUNTADMIN;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b56ef8-8cd2-440e-930d-15190fe5da6e",
   "metadata": {
    "collapsed": false,
    "name": "md_setup_ev"
   },
   "source": [
    "# Setup Snowflake\n",
    "## Create an External Volume\n",
    "To create an external volume, complete the instructions for your cloud storage service:\n",
    "- [Accessing Amazon S3 using external volumes](https://docs.snowflake.com/en/user-guide/tables-iceberg-configure-external-volume-s3)\n",
    "- [Accessing Microsoft Azure Storage using external volumes](https://docs.snowflake.com/en/user-guide/tables-iceberg-configure-external-volume-azure)\n",
    "\n",
    "Remember from the Overview section, your Snowflake account must be in the same region as your external volume location. And to use the Sentiment LLM function, [supported regions](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions#availability) currently include:\n",
    "- AWS US West 2 (Oregon)\n",
    "- AWS US East 1 (N. Virginia)\n",
    "- AWS Europe Central 1 (Frankfurt)\n",
    "- Azure East US 2 (Virginia)\n",
    "- Azure West Europe (Netherlands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c7e6d-3416-4c91-a474-8ebec71448e9",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_create_ev"
   },
   "outputs": [],
   "source": [
    "-- Use accountadmin role to create an external volume\n",
    "USE ROLE accountadmin;\n",
    "\n",
    "-- Create an external volume\n",
    "CREATE OR REPLACE EXTERNAL VOLUME iceberg_cortex_vol\n",
    "   STORAGE_LOCATIONS =\n",
    "      (\n",
    "         (\n",
    "            NAME = 'my-s3-us-west-2'\n",
    "            STORAGE_PROVIDER = 'S3'\n",
    "            STORAGE_BASE_URL = 's3://iceberg-sentiment/'\n",
    "            \n",
    "            STORAGE_AWS_ROLE_ARN = '<your_aws_role_Arn>'      #'arn:aws:iam::719851637562:role/Snf-iceberg'\n",
    "            STORAGE_AWS_EXTERNAL_ID ='<your_external_id>'     #'my_external_id'\n",
    "         )\n",
    "      );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76cdb8-b8a9-4034-88ef-683cf1d54068",
   "metadata": {
    "collapsed": false,
    "name": "md_iceberg_catalogs"
   },
   "source": [
    "## Create an Iceberg Table\n",
    "Iceberg Tables can currently use Snowflake, AWS Glue, or object storage as the catalog. In public preview soon, Snowflake can use catalog integration with an Iceberg REST endpoint. In this quickstart, use Snowflake as the catalog to allow read and write operations to the table. More information about integrating catalogs can be found [here](https://docs.snowflake.com/en/user-guide/tables-iceberg-configure-catalog-integration).\n",
    "\n",
    "Create an Iceberg Table referencing the external volume you just created. You can specify `BASE_LOCATION` to instruct Snowflake where to write table data and metadata, or leave empty to write data and metadata to the location specified in the external volume definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_create_iceberg_table"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE ICEBERG TABLE iceberg_demo.public.product_reviews (\n",
    "    id STRING,\n",
    "    product_name STRING,\n",
    "    product_id STRING,\n",
    "    reviewer_name STRING,\n",
    "    review_date DATE,\n",
    "    review STRING,\n",
    "    sentiment FLOAT\n",
    ")\n",
    "    CATALOG = 'SNOWFLAKE'\n",
    "    EXTERNAL_VOLUME = 'iceberg_cortex_vol'\n",
    "    BASE_LOCATION = 'demo/product_reviews/'\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89570d-c063-44f2-9c34-2d8e229dbb9c",
   "metadata": {
    "collapsed": false,
    "name": "md_load"
   },
   "source": [
    "# Load CSV files into Iceberg via Snowpark Python\n",
    "There are multiple ways to load new data into Snowflake-managed Iceberg Tables including INSERT, [COPY INTO](https://docs.snowflake.com/en/sql-reference/sql/copy-into-table), and [Snowpipe](https://docs.snowflake.com/en/user-guide/data-load-snowpipe-auto).\n",
    "\n",
    "For this quickstart, we will use Snowpark to write CSV files from dataframes into the Iceberg Table. Snowflake will write Parquet files and Iceberg metadata to your external volume.\n",
    "\n",
    "First, create an external stage and file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5639abc-f09b-4816-a9ed-d3d150970ea6",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_file_setup"
   },
   "outputs": [],
   "source": [
    "-- Create a file format\n",
    "CREATE OR REPLACE FILE FORMAT iceberg_demo.public.csv_ff\n",
    "    TYPE = 'CSV'\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "    SKIP_HEADER = 1;\n",
    "\n",
    "-- Create an external stage to read CSV files from an S3 bucket in-place\n",
    "CREATE OR REPLACE STAGE iceberg_demo.public.files\n",
    "    URL = 's3://sfquickstarts/iceberg_cortex/'\n",
    "    FILE_FORMAT = iceberg_demo.public.csv_ff\n",
    "    DIRECTORY = (ENABLE = TRUE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules and create a session\n",
    "import json\n",
    "from snowflake.snowpark import Session\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bfc44-4b44-4b55-8773-def2557abec9",
   "metadata": {
    "language": "python",
    "name": "py_create_schema"
   },
   "outputs": [],
   "source": [
    "# Create a schema Snowpark dataframe matching the CSV files\n",
    "reviews_schema = T.StructType([T.StructField(\"ID\", T.StringType()),\n",
    "                               T.StructField(\"PRODUCT_NAME\", T.StringType()),\n",
    "                               T.StructField(\"PRODUCT_ID\", T.StringType()),\n",
    "                               T.StructField(\"REVIEWER_NAME\", T.StringType()),\n",
    "                               T.StructField(\"REVIEW_DATE\", T.DateType()),\n",
    "                               T.StructField(\"REVIEW\", T.StringType()),\n",
    "                               T.StructField(\"SENTIMENT\", T.FloatType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ffe28e-db1e-4a91-af82-7d2f36350b66",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "py_jan_df"
   },
   "outputs": [],
   "source": [
    "# Read the January product reviews into a dataframe\n",
    "jan_df = session.read \\\n",
    "    .schema(reviews_schema) \\\n",
    "    .option(\"skip_header\", 1) \\\n",
    "    .option(\"field_optionally_enclosed_by\", '\"') \\\n",
    "    .csv(\"@iceberg_demo.public.files/product_reviews_jan_24.csv\")\n",
    "\n",
    "# View the dataframe\n",
    "jan_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d25722-6560-4716-b3e6-d558bd1415ed",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "py_jan_df_write"
   },
   "outputs": [],
   "source": [
    "# Write the dataframe to the Iceberg Table\n",
    "jan_df.write.mode(\"append\").save_as_table(\"iceberg_demo.public.product_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7508f0-eef4-4d3b-8694-22af86ec2ed5",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM iceberg_demo.public.product_reviews;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22fa91f-31c3-48ba-bbf8-a889ab8ccbc0",
   "metadata": {
    "collapsed": false,
    "name": "md_load_complete"
   },
   "source": [
    "You now see metadata files and Parquet data files in your object storage, whether youâ€™re using Amazon S3 or Azure storage.\n",
    "\n",
    "![iceberg_files](https://github.com/Snowflake-Labs/sfquickstarts/blob/master/site/sfguides/src/cortex_ai_sentiment_iceberg/assets/iceberg_files.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9fb1f-5f0c-4547-9dca-66c5c0f6d1a1",
   "metadata": {
    "collapsed": false,
    "name": "md_cortex"
   },
   "source": [
    "# Snowflake Cortex LLM Functions\n",
    "Now you can query the Iceberg Table using LLM functions from Snowflake Cortex AI. Run the query below to calculate sentiment scores for product reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f04d3-98c4-4697-976a-267b7fb7914c",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_reviews_select"
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "    id,\n",
    "    product_name,\n",
    "    review_date,\n",
    "    snowflake.cortex.sentiment(review) as review_sentiment\n",
    "FROM iceberg_demo.public.product_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec430b-3171-45e4-9059-570f21b4f06f",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_update"
   },
   "outputs": [],
   "source": [
    "-- Write the sentiment scores back to the Iceberg Table.\n",
    "UPDATE iceberg_demo.public.product_reviews as pr\n",
    "   SET sentiment = jan.review_sentiment\n",
    "  FROM {{sql_reviews_select}} AS jan\n",
    " WHERE jan.id = pr.id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e131af80-db4c-4de4-8fef-3ba4f9ee163c",
   "metadata": {
    "collapsed": false,
    "name": "md_create_pipeline"
   },
   "source": [
    "# Create a CDC Pipeline\n",
    "Suppose new product reviews continue to be generated, stored as new CSV files, and you'd like to use Snowflake to automatically compute sentiment scores on new product reviews.\n",
    "\n",
    "[Streams on Directory Tables](https://docs.snowflake.com/en/user-guide/data-load-dirtables-pipeline) can detect new files in stages, perform computation, and store results. LLM functions from Snowflake Cortex can be called in these pipelines, writing results to Iceberg Tables.\n",
    "\n",
    "To simulate this, create a Stream on the Iceberg Table to detect new product reviews loaded to the table. On a schedule, a Serverless Task will call the SENTIMENT function on to incrementally process new records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090e499-5e0e-4bbf-99db-3103314d5582",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_create_pipeline"
   },
   "outputs": [],
   "source": [
    "-- Create a Stream to detect new product review records in the Iceberg Table\n",
    "CREATE STREAM iceberg_demo.public.product_reviews_stream ON TABLE iceberg_demo.public.product_reviews;\n",
    "\n",
    "-- Create a Serverless Task to add sentiment for new records from the Stream\n",
    "CREATE OR REPLACE TASK iceberg_demo.public.cortex_sentiment_score\n",
    "    SCHEDULE = 'USING CRON 0 0 * * * America/Los_Angeles'\n",
    "    USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL'\n",
    "AS\n",
    "UPDATE iceberg_demo.public.product_reviews AS pr\n",
    "   SET sentiment = snowflake.cortex.sentiment(prs.review)\n",
    "  FROM iceberg_demo.public.product_reviews_stream AS prs\n",
    " WHERE prs.id = pr.id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080fa4d-3b6c-469e-8e0e-f502e707f053",
   "metadata": {
    "collapsed": false,
    "name": "md_feb_df"
   },
   "source": [
    "Now see the incremental processing pipeline in action. Create a dataframe for February product reviews and write it to the Iceberg Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb3b62-6823-4292-a4b8-d84309c98bc5",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "py_feb_df"
   },
   "outputs": [],
   "source": [
    "feb_df = session.read \\\n",
    "    .schema(reviews_schema) \\\n",
    "    .option(\"skip_header\", 1) \\\n",
    "    .option(\"field_optionally_enclosed_by\", '\"') \\\n",
    "    .csv(\"@iceberg_demo.public.files/product_reviews_feb_24.csv\")\n",
    "\n",
    "feb_df.write.mode(\"append\").save_as_table(\"iceberg_demo.public.product_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f10f72-e47c-4662-abbb-a880b37d3bf4",
   "metadata": {
    "collapsed": false,
    "name": "md_reviews"
   },
   "source": [
    "The Task will execute on the specified schedule. Manually trigger the task to calculate sentiment scores for February product reviews, writing the results back to the Iceberg Table. Now, you should see the February product reviews and sentiment scores.\n",
    "\n",
    "For example, for each product, what was the change in sentiment from January to February? Run the query below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cd2e4-335e-4d77-9667-89fc2ca452f1",
   "metadata": {
    "language": "sql",
    "name": "run_task"
   },
   "outputs": [],
   "source": [
    "-- Manually trigger Task\n",
    "EXECUTE task cortex_sentiment_score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58a206-4d87-47c6-a460-4c07235126c5",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_reviews"
   },
   "outputs": [],
   "source": [
    "-- Sentiment change from January to February\n",
    "WITH jan AS (\n",
    "    SELECT\n",
    "        product_name,\n",
    "        AVG(sentiment) AS avg_sentiment\n",
    "    FROM iceberg_demo.public.product_reviews\n",
    "    WHERE MONTHNAME(review_date) = 'Jan'\n",
    "    GROUP BY 1\n",
    ")\n",
    ", feb AS (\n",
    "    SELECT\n",
    "        product_name,\n",
    "        AVG(sentiment) AS avg_sentiment\n",
    "    FROM iceberg_demo.public.product_reviews\n",
    "    WHERE MONTHNAME(review_date) = 'Feb'\n",
    "    GROUP BY 1\n",
    ")\n",
    "SELECT\n",
    "    COALESCE(j.product_name, f.product_name) AS product_name,\n",
    "    j.avg_sentiment AS jan_sentiment,\n",
    "    f.avg_sentiment AS feb_sentiment,\n",
    "    feb_sentiment - jan_sentiment AS sentiment_diff\n",
    "FROM jan j\n",
    "FULL OUTER JOIN feb f\n",
    "    ON j.product_name = f.product_name\n",
    "ORDER BY sentiment_diff DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e846d4-6377-4a67-a004-912086e0d8d3",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "py_chart"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.bar_chart(sql_reviews.to_df(), x='PRODUCT_NAME', y='SENTIMENT_DIFF')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
